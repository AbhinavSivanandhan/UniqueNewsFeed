import sys
import tweepy
import json
import nltk
import numpy as np
import random
import string 
import wordninja #split tag
from textblob import TextBlob
from langdetect import detect
from translate import Translator #for hindi translation in tweets
import re
from profanityfilter import ProfanityFilter
pf = ProfanityFilter()
translation=''
dst=''
#import requests //no use as_of now, but will need if Maxrequests error occurs. Needs a proxy to sustain the program in the long run.
'''
proxies = {'http': "socks5://myproxy:9191"}
requests.get('http://example.org', proxies=proxies)
'''
#Authentication
consumer_key = 'kjfMjfMGWI4X1ZpLjedXLpvSe'
consumer_secret = 'usXTaDx5Uu2r0Gqf0gAb7UzUeGBqDwlASOpeke0kkAJGHo7fHA'
access_token = '994471668-AScInzntHQ3m4R1uUiLAf3y9cSZsKCOUOpo9ACPe'
access_token_secret = 'vA3WDxZBvH7uHd0xu6SrwYXSkXnbhVWhkyWrOY69fkwLK'
val=0

import datetime         #remove whole module if it messes with the tag log file
#write today date ,for comparing purposes
with open("datetoday.txt", mode='w') as file:
    file.write('%s\n' % 
               (datetime.datetime.now()))
#date status last opened
f5=open('dateopened.txt','r',errors='ignore')
data=f5.read()
f5.close()
#print(data)
d=data.split()
print(d)
od=d[0][8]+d[0][9]
#reopen today date
f10=open('datetoday.txt','r',errors='ignore')
data=f10.read()
f10.close()
#print(data)
d=data.split()
print(d)
td=d[0][8]+d[0][9]
#compare both
if od==td:
    pass
else:
    f15=open('taglist.txt','w',errors='ignore') #truncates all tags of the day
    da="Monday\nTuesday\nWednesday\nThursday\nFriday\nSaturday\nSunday\n" #Avoids IndexError on first run+eliminates a bunch of redundant boring topics that twitter regularly provides
    f15.write(da) 
    f15.close()
    with open("dateopened.txt", mode='w') as file:
        file.write('%s\n' % 
               (datetime.datetime.now()))
  
 #WOE_ID=1
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
api = tweepy.API(auth)
flag=0
# Where On Earth ID for world is 1 from http://woeid.rosselliot.co.nz/
#write code for equivalent of goto function
#write code here to give choices between world, national, state, regional
print("1.World 2.India 3.Tamil Nadu 4.Vellore")

ch=input()
if ch==1:
    WOE_ID = 1 # go to website and take second val woeid
elif ch==2:
    WOE_ID = 23424848
elif ch==3:
    WOE_ID = 2345758
elif ch==4:
    WOE_ID = 2295285
else:
    WOE_ID = 23424848
#  try to write reddit preference inherit. That gives interesting general topics, other than news
    
    
trends = api.trends_place(WOE_ID)
 
trends = json.loads(json.dumps(trends, indent=1))
newscount=0
for trend in trends[0]["trends"]: #write code to write traversed tags into a document, do similarity analysis to see _if feed has done, acts _as feed book mark _and eliminates similar tags
    # define function checkiftrendisread(trend) to read from file where seemore level of newsreading has been done, skip those tags
    print(trend["name"].strip('#'))
    public_tweets = api.search(trend["name"].strip('#'))
    #if_ random feed generation is expected, the below code. else_ prioritize
    f=open('taglist.txt','a')
    tag=trend["name"].strip('#')
    
    #tag=wordninja.split(tag)
    re_outer = re.compile(r'([^A-Z ])([A-Z])')
    re_inner = re.compile(r'(?<!^)([A-Z])([^A-Z])')
    tag1=re_outer.sub(r'\1 \2', re_inner.sub(r' \1\2', tag))
    langh=detect(tag1)
    ''' sent_str = ""
    for i in tag1:
        sent_str += str(i) + " "
    sent_str = sent_str[:-1]
    tag=sent_str'''

    ##
    f2=open('taglist.txt','r')
    raw=f2.read() #ra!=ra.lowrer. this messed up the hashtags
    
    f2.close()
    sent_tokens = nltk.sent_tokenize(raw)
    word_tokens = nltk.word_tokenize(raw)
    lemmer = nltk.stem.WordNetLemmatizer()
    def LemTokens(tokens):
        return [lemmer.lemmatize(token) for token in tokens]
    remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)
    def LemNormalize(text):
        return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))  
    
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    def response(user_response):
        robo_response=''
        sent_tokens.append(user_response)
        TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')
        tfidf = TfidfVec.fit_transform(sent_tokens)
        vals = cosine_similarity(tfidf[-1], tfidf)
    #print(vals)
        idx=vals.argsort()[0][-2]
        flat = vals.flatten()
        flat.sort()
        req_tfidf = flat[-2]
        return req_tfidf
    
    #print("ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type 'bye'")
    user_response = tag1
    #user_response=sent_str
    #user_response=user_response.lower()
    #print("ROBO: ",end="")
    val=response(user_response)
    print(val)
    if val>0.1:
        continue
    else:
        f.write(tag1)
        f.write('\n')
        print('Do you want to see more (y/n/s)?') #write code for collaborative filtering, i.e collect y tags in a seperate document, also calculate average y per num of obs to find it person actually like or is just free
        c1=input()
    flag=0
    maxcount=0
    countp=0
    countn=0
    countm=0
    print('\n')
    
    if c1=='y':     
        
        for tweet in public_tweets:
            translation=''
            dst=''
            if maxcount<4:
                lang=detect(tweet.text)
                if(lang=='en'):
                    analysis = TextBlob(tweet.text)
                    translation=tweet.text
                else:
                    if lang=='hi':   #try this out #it does not translate if hindi words are lesser than english
                        translator= Translator(from_lang="hindi",to_lang="english")
                        translation = translator.translate(tweet.text)
                        dst='\n <THIS IS TRANSLATED FROM HINDI> \n'
                    if lang=='ta':  
                        translator= Translator(from_lang="tamil",to_lang="english")
                        translation = translator.translate(tweet.text)
                        dst='\n <THIS IS TRANSLATED FROM TAMIL> \n'                    
                analysis = TextBlob(translation)   
           #     print(analysis.sentiment)
                if(analysis.sentiment[0]>0 and countp<2):
                    print(tweet.text)
                    print('Positive')
                    countp=countp+1
                    maxcount=maxcount+1
                elif(analysis.sentiment[0]<0 and countn<2):
                    print(tweet.text)
                    print('Negative')
                    countn=countn+1
                    maxcount=maxcount+1
                elif(analysis.sentiment[0]==0 and countm<2):
                    print(tweet.text)
                    print('Neutral')
                    maxcount=maxcount+1
                    countm=countm+1
                else:
                    continue
                print("\n")
                print(translation)
                print(dst)
                print(".............................................")
                
    elif c1=='s':
        for tweet in public_tweets:
            lang=detect(tweet.text)
            if lang=='en':
                analysis = TextBlob(tweet.text)
                translation=tweet.text
            if lang=='hi':   #try this out #it does not translate if hindi words are lesser than english
                translator= Translator(from_lang="hindi",to_lang="english")
                translation = translator.translate(tweet.text)
                analysis = TextBlob(translation)
                print(translation)
                print('\n <THIS IS TRANSLATED FROM HINDI> \n')
            if lang=='ta':  
                translator= Translator(from_lang="tamil",to_lang="english")
                translation = translator.translate(tweet.text)
                analysis = TextBlob(translation)
                print(translation)
                print('\n <THIS IS TRANSLATED FROM TAMIL> \n')
            print(tweet.text)
            print("\n")
            if(analysis.sentiment[0]>0 and countp<2):
                print('Positive')
            elif(analysis.sentiment[0]<0 and countn<2):
                print('Negative')
            elif(analysis.sentiment[0]==0 and countm<2):
                print('Neutral')
            else:
                pass
           # print(analysis.sentiment)
            print(".............................................")

    else:
        print('-*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*_*\n')
    newscount=newscount+1
    if newscount%5==0:
        print('Continue showing further feed(y/n)?')
        c2=input()
        if c2=='y':
            print('\n')
        else:
            sys.exit()

